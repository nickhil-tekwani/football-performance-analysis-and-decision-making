{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05db993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def print_directory_contents(path):\n",
    "    for item in os.listdir(path):\n",
    "        if os.path.isdir(os.path.join(path, item)):\n",
    "            print(f\"\\n- {item}/\")\n",
    "            print_directory_contents(os.path.join(path, item))\n",
    "        else:\n",
    "            print(f\"  - {item}\")\n",
    "\n",
    "# Use \".\" to refer to the current directory\n",
    "#print_directory_contents(\".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9d6358",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "88f2c5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def parse_event_data(events_file_path):\n",
    "    with open(events_file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    events = data\n",
    "\n",
    "    # Extract the relevant data for our model\n",
    "    pass_events = []\n",
    "    shot_events = []\n",
    "\n",
    "    for event in events:\n",
    "        if 'type' in event and event['type']['name'] == 'Pass':\n",
    "            period = event['period']['name'] if isinstance(event['period'], dict) else event['period']\n",
    "            pass_events.append({\n",
    "                'id': event['id'],\n",
    "                'timestamp': event['timestamp'],\n",
    "                'period': period,\n",
    "                'duration': event['duration'],\n",
    "                'possession': event['possession'],\n",
    "                'team': event['team']['name'],\n",
    "                'player': event['player']['name'],\n",
    "                'location': event['location'],\n",
    "                'pass_end_location': event['pass']['end_location'],\n",
    "                'pass_height': event['pass']['height']['name'],\n",
    "                'pass_length': event['pass']['length'],\n",
    "                'pass_angle': event['pass']['angle'],\n",
    "                'pass_type': event['pass']['type']['name'] if 'type' in event['pass'] else None,\n",
    "                'pass_outcome': event['pass']['outcome']['name'] if 'outcome' in event['pass'] else None,\n",
    "                'pass_body_part': event['pass']['body_part']['name'] if 'body_part' in event['pass'] else None\n",
    "            })\n",
    "        elif 'type' in event and event['type']['name'] == 'Shot':\n",
    "            period = event['period']['name'] if isinstance(event['period'], dict) else event['period']\n",
    "            shot_events.append({\n",
    "                'id': event['id'],\n",
    "                'timestamp': event['timestamp'],\n",
    "                'period': period,\n",
    "                'duration': event['duration'],\n",
    "                'possession': event['possession'],\n",
    "                'team': event['team']['name'],\n",
    "                'player': event['player']['name'],\n",
    "                'location': event['location'],\n",
    "                'shot_end_location': event['shot']['end_location'],\n",
    "                'shot_outcome': event['shot']['outcome']['name'] if 'outcome' in event['shot'] else None,\n",
    "                'shot_type': event['shot']['type']['name'] if 'type' in event['shot'] else None,\n",
    "                'shot_body_part': event['shot']['body_part']['name'] if 'body_part' in event['shot'] else None,\n",
    "                'shot_technique': event['shot']['technique']['name'] if 'technique' in event['shot'] else None,\n",
    "                'shot_first_time': event['shot']['first_time'] if 'first_time' in event['shot'] else None\n",
    "            })\n",
    "\n",
    "    pass_df = pd.DataFrame(pass_events)\n",
    "    shot_df = pd.DataFrame(shot_events)\n",
    "\n",
    "    return pass_df, shot_df\n",
    "\n",
    "\n",
    "# Define function to merge event data with lineup data\n",
    "# def merge_data(pass_df, shot_df, lineup_file_path):\n",
    "#     # Load lineup data from JSON file\n",
    "#     with open(lineup_file_path, 'r', encoding='utf-8') as file:\n",
    "#         data = json.load(file)\n",
    "\n",
    "#     # Create lineup DataFrame\n",
    "#     players = []\n",
    "#     for team in data:\n",
    "#         for player in team['lineup']:\n",
    "#             player_dict = {\n",
    "#                 'player_name': None,\n",
    "#                 'position_name': None,\n",
    "#             }\n",
    "#             if 'player' in player:\n",
    "#                 player_dict['player_name'] = player['player']['name']\n",
    "#             if 'position' in player:\n",
    "#                 player_dict['position_name'] = player['position']['name']\n",
    "#             players.append(player_dict)\n",
    "#     lineup_df = pd.DataFrame(players)\n",
    "\n",
    "#     # Merge pass data with lineup data\n",
    "#     pass_df = pd.merge(pass_df, lineup_df[['player_name', 'position_name']], left_on='player', right_on='player_name', how='left')\n",
    "#     pass_df.drop('player_name', axis=1, inplace=True)\n",
    "\n",
    "#     # Merge shot data with lineup data\n",
    "#     shot_df = pd.merge(shot_df, lineup_df[['player_name', 'position_name']], left_on='player', right_on='player_name', how='left')\n",
    "#     shot_df.drop('player_name', axis=1, inplace=True)\n",
    "\n",
    "#     return pass_df, shot_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a325f1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(pass_df, shot_df, lineup_file_path):\n",
    "    # Load lineup data from JSON file\n",
    "    with open(lineup_file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Create lineup DataFrame\n",
    "    players = []\n",
    "    for team in data:\n",
    "        for player in team['lineup']:\n",
    "            player_dict = {\n",
    "                'player_name': None,\n",
    "                'position_name': None,\n",
    "            }\n",
    "            if 'player' in player:\n",
    "                player_dict['player_name'] = player['player']['name']\n",
    "            if 'position' in player:\n",
    "                player_dict['position_name'] = player['position']['name']\n",
    "            players.append(player_dict)\n",
    "    lineup_df = pd.DataFrame(players)\n",
    "\n",
    "    # Merge pass data with lineup data\n",
    "    pass_df = pd.merge(pass_df, lineup_df[['player_name', 'position_name']], left_on='player', right_on='player_name', how='left')\n",
    "    pass_df.drop('player_name', axis=1, inplace=True)\n",
    "\n",
    "    # Merge shot data with lineup data\n",
    "    shot_df = pd.merge(shot_df, lineup_df[['player_name', 'position_name']], left_on='player', right_on='player_name', how='left')\n",
    "    shot_df.drop('player_name', axis=1, inplace=True)\n",
    "\n",
    "    # Extract additional columns from the shot data\n",
    "    shot_df['shot_distance'] = np.sqrt((shot_df['location'].str[0] - shot_df['shot_end_location'].str[0]) ** 2 + (shot_df['location'].str[1] - shot_df['shot_end_location'].str[1]) ** 2)\n",
    "    shot_df['shot_body_part'] = shot_df['shot'].apply(lambda x: x['body_part']['name'] if 'body_part' in x else None)\n",
    "    shot_df['shot_first_time'] = shot_df['shot'].apply(lambda x: x['first_time'] if 'first_time' in x else None)\n",
    "    shot_df['shot_technique'] = shot_df['shot'].apply(lambda x: x['technique']['name'] if 'technique' in x else None)\n",
    "\n",
    "    return pass_df, shot_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "23fe1ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "\n",
    "# Define function to preprocess the data\n",
    "def preprocess_data(pass_df, shot_df):\n",
    "    # Convert timestamp to seconds\n",
    "    pass_df['timestamp'] = pd.to_timedelta(pass_df['timestamp']).dt.total_seconds()\n",
    "    shot_df['timestamp'] = pd.to_timedelta(shot_df['timestamp']).dt.total_seconds()\n",
    "\n",
    "    # Calculate pass angle from the pass end location and the player's location\n",
    "    pass_end_x, pass_end_y = zip(*pass_df['pass_end_location'])\n",
    "    player_x, player_y = zip(*pass_df['location'])\n",
    "    pass_df['pass_angle'] = np.degrees(np.arctan2(np.subtract(pass_end_y, player_y), np.subtract(pass_end_x, player_x)))\n",
    "\n",
    "    # Calculate pass length from the player's location and the pass end location\n",
    "    pass_df['pass_length'] = np.sqrt((np.array(pass_end_x) - np.array(player_x)) ** 2 + (np.array(pass_end_y) - np.array(player_y)) ** 2)\n",
    "\n",
    "    # Scale the numerical features\n",
    "    scaler = StandardScaler()\n",
    "    pass_df[['timestamp', 'pass_length', 'pass_angle']] = scaler.fit_transform(pass_df[['timestamp', 'pass_length', 'pass_angle']])\n",
    "    shot_df[['timestamp']] = scaler.fit_transform(shot_df[['timestamp']])\n",
    "    shot_df['shot_distance'] = np.sqrt((shot_df['location'].str[0] - shot_df['shot_end_location'].str[0]) ** 2 + (shot_df['location'].str[1] - shot_df['shot_end_location'].str[1]) ** 2)\n",
    "\n",
    "    return pass_df, shot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7e2b6fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     id     timestamp  period  duration  \\\n",
      "0  f86a49e6-2d11-4e89-8c54-a736720a8b0d  00:00:00.793       1  1.106021   \n",
      "1  43c872ae-0e27-4a49-8462-342bef278580  00:00:02.565       1  1.307097   \n",
      "2  d814f6ad-99ef-489a-9040-4e903deca237  00:00:04.474       1  1.219923   \n",
      "3  b32b2820-3fe9-4435-842d-f3200df60088  00:00:06.664       1  1.480582   \n",
      "4  abced20e-c44a-447d-92a0-e5028cbcfeed  00:00:09.179       1  2.694161   \n",
      "\n",
      "   possession                 team                 player      location  \\\n",
      "0           2  Manchester City WFC    Khadija Monifa Shaw  [60.0, 40.0]   \n",
      "1           2  Manchester City WFC           Yui Hasegawa  [48.4, 39.8]   \n",
      "2           2  Manchester City WFC  Laia Aleixandri López  [35.5, 49.2]   \n",
      "3           2  Manchester City WFC         Alex Greenwood  [35.3, 27.1]   \n",
      "4           2  Manchester City WFC       Esme Beth Morgan   [36.2, 7.1]   \n",
      "\n",
      "  pass_end_location  pass_height  pass_length  pass_angle pass_type  \\\n",
      "0      [47.9, 38.5]  Ground Pass    12.192620   -3.018255  Kick Off   \n",
      "1      [34.9, 51.1]  Ground Pass    17.605112    2.444673      None   \n",
      "2      [35.0, 31.7]  Ground Pass    17.507141   -1.599360      None   \n",
      "3       [38.1, 7.2]  Ground Pass    20.096020   -1.431010      None   \n",
      "4       [9.6, 38.9]  Ground Pass    41.458412    2.267388      None   \n",
      "\n",
      "  pass_outcome pass_body_part  \n",
      "0         None     Right Foot  \n",
      "1         None      Left Foot  \n",
      "2         None     Right Foot  \n",
      "3         None     Right Foot  \n",
      "4         None     Right Foot  \n",
      "                                     id     timestamp  period  duration  \\\n",
      "0  e0a55292-2c2e-42f0-9a84-574e82b614c2  00:04:30.882       1  1.551493   \n",
      "1  1f3dd413-eae3-4b1a-865f-0b98c1ca711f  00:05:24.355       1  0.271861   \n",
      "2  247dc3f1-3b3b-4ab4-9eb4-4a88b43c4e09  00:05:26.578       1  0.060900   \n",
      "3  6a0f2106-ad7a-4e82-b083-24834fe4bb08  00:06:05.223       1  0.039053   \n",
      "4  a43e6cf6-7f6e-4598-82cf-bad5dfee22e2  00:13:17.377       1  0.873658   \n",
      "\n",
      "   possession                 team                               player  \\\n",
      "0           9  Manchester City WFC                Laia Aleixandri López   \n",
      "1          10  Manchester City WFC  Deyna Cristina Castellanos Naujenis   \n",
      "2          10  Manchester City WFC                          Chloe Kelly   \n",
      "3          11  Manchester City WFC  Deyna Cristina Castellanos Naujenis   \n",
      "4          23  Manchester City WFC                          Chloe Kelly   \n",
      "\n",
      "              location   shot_end_location shot_outcome  shot_type  \\\n",
      "0  [109.8, 46.8, 2.03]       [113.9, 34.4]      Wayward  Open Play   \n",
      "1  [114.0, 40.9, 1.58]  [118.4, 42.5, 1.3]        Saved  Open Play   \n",
      "2  [117.7, 50.8, 0.25]       [118.1, 49.4]      Blocked  Open Play   \n",
      "3  [113.3, 38.8, 0.53]       [114.5, 39.1]      Blocked  Open Play   \n",
      "4    [99.0, 51.8, 0.0]  [120.0, 38.7, 2.9]         Post  Open Play   \n",
      "\n",
      "  shot_body_part shot_technique shot_first_time  \n",
      "0           Head         Normal            None  \n",
      "1     Right Foot         Volley            True  \n",
      "2     Right Foot    Half Volley            True  \n",
      "3     Right Foot    Half Volley            True  \n",
      "4     Right Foot         Normal            None  \n"
     ]
    }
   ],
   "source": [
    "# Test parse_event_data function\n",
    "pass_df, shot_df = parse_event_data('./statsbomb json files/g2312152/ManCity_LeicesterCity_events.json')\n",
    "print(pass_df.head())\n",
    "print(shot_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c4ecbcf2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'shot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'shot'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Test merge_data function\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m pass_df, shot_df \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpass_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshot_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./statsbomb json files/g2312152/ManCity_LeicesterCity_lineups.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(pass_df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(shot_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[1;32mIn[80], line 31\u001b[0m, in \u001b[0;36mmerge_data\u001b[1;34m(pass_df, shot_df, lineup_file_path)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Extract additional columns from the shot data\u001b[39;00m\n\u001b[0;32m     30\u001b[0m shot_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshot_distance\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt((shot_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m shot_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshot_end_location\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m (shot_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m shot_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshot_end_location\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m shot_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshot_body_part\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mshot_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mshot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody_part\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody_part\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     32\u001b[0m shot_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshot_first_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m shot_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshot\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_time\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     33\u001b[0m shot_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshot_technique\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m shot_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshot\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtechnique\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtechnique\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'shot'"
     ]
    }
   ],
   "source": [
    "# Test merge_data function\n",
    "pass_df, shot_df = merge_data(pass_df, shot_df, './statsbomb json files/g2312152/ManCity_LeicesterCity_lineups.json')\n",
    "print(pass_df.head())\n",
    "print(shot_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738e05ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test preprocess_data function\n",
    "pass_df, shot_df = preprocess_data(pass_df[['timestamp', 'location', 'pass_end_location', 'pass_height', 'pass_type']], shot_df[['timestamp', 'location', 'shot_end_location', 'shot_type']])\n",
    "print(pass_df.head())\n",
    "print(shot_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcb6f16",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fb28125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def build_model(pass_df, shot_df):\n",
    "    # Prepare the data for the model\n",
    "    X_pass = pass_df[['timestamp', 'location', 'pass_end_location', 'pass_length', 'pass_angle', 'pass_height', 'pass_type']]\n",
    "    X_shot = shot_df[['timestamp', 'location', 'shot_end_location', 'shot_distance', 'shot_type', 'shot_body_part', 'shot_first_time', 'shot_technique']]\n",
    "    y_pass = np.zeros(len(pass_df))\n",
    "    y_shot = np.ones(len(shot_df))\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_pass_train, X_pass_test, y_pass_train, y_pass_test = train_test_split(X_pass, y_pass, test_size=0.2, random_state=42)\n",
    "    X_shot_train, X_shot_test, y_shot_train, y_shot_test = train_test_split(X_shot, y_shot, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Combine the pass and shot data\n",
    "    X_train = pd.concat([X_pass_train, X_shot_train])\n",
    "    y_train = np.concatenate([y_pass_train, y_shot_train])\n",
    "    X_test = pd.concat([X_pass_test, X_shot_test])\n",
    "    y_test = np.concatenate([y_pass_test, y_shot_test])\n",
    "\n",
    "    # Scale the numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_train[['timestamp', 'pass_length', 'pass_angle', 'shot_distance']] = scaler.fit_transform(X_train[['timestamp', 'pass_length', 'pass_angle', 'shot_distance']])\n",
    "    X_test[['timestamp', 'pass_length', 'pass_angle', 'shot_distance']] = scaler.transform(X_test[['timestamp', 'pass_length', 'pass_angle', 'shot_distance']])\n",
    "\n",
    "    # One-hot encode the categorical features\n",
    "    X_train = pd.get_dummies(X_train, columns=['pass_height', 'pass_type', 'shot_type', 'shot_body_part', 'shot_first_time', 'shot_technique'])\n",
    "    X_test = pd.get_dummies(X_test, columns=['pass_height', 'pass_type', 'shot_type', 'shot_body_part', 'shot_first_time', 'shot_technique'])\n",
    "\n",
    "    # Train the model\n",
    "    model = LogisticRegression(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "\n",
    "    print(f\"Training score: {train_score}\")\n",
    "    print(f\"Testing score: {test_score}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c120f1bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['shot_body_part', 'shot_first_time', 'shot_technique'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpass_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshot_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[74], line 7\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(pass_df, shot_df)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_model\u001b[39m(pass_df, shot_df):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Prepare the data for the model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     X_pass \u001b[38;5;241m=\u001b[39m pass_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpass_end_location\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpass_length\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpass_angle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpass_height\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpass_type\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m----> 7\u001b[0m     X_shot \u001b[38;5;241m=\u001b[39m \u001b[43mshot_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimestamp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mshot_end_location\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mshot_distance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mshot_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mshot_body_part\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mshot_first_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mshot_technique\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      8\u001b[0m     y_pass \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(pass_df))\n\u001b[0;32m      9\u001b[0m     y_shot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(shot_df))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['shot_body_part', 'shot_first_time', 'shot_technique'] not in index\""
     ]
    }
   ],
   "source": [
    "model = build_model(pass_df, shot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bffd20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
